#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å–®ä¸€è»Šæ‰‹åœˆé€Ÿåˆ†ææ¨¡çµ„
æä¾›è»Šæ‰‹åœˆé€Ÿè¡¨ç¾çš„æ·±åº¦åˆ†æ
"""

import os
import json
import pickle
import numpy as np
import pandas as pd
from datetime import datetime
from typing import Dict, Any, Optional, List
from prettytable import PrettyTable

class SingleDriverLaptimeAnalysis:
    """å–®ä¸€è»Šæ‰‹åœˆé€Ÿåˆ†æå™¨"""
    
    def __init__(self, data_loader, year: int, race: str, session: str):
        self.data_loader = data_loader
        self.year = year
        self.race = race
        self.session = session
        self.cache_dir = "cache"
        
        # ç¢ºä¿ç·©å­˜ç›®éŒ„å­˜åœ¨
        os.makedirs(self.cache_dir, exist_ok=True)
    
    def analyze_lap_times(self, driver: str, **kwargs) -> Dict[str, Any]:
        """åˆ†æè»Šæ‰‹åœˆé€Ÿè¡¨ç¾
        
        Args:
            driver: è»Šæ‰‹ä»£ç¢¼ (å¦‚ 'VER', 'LEC')
            
        Returns:
            Dict: åŒ…å«åœˆé€Ÿåˆ†æçµæœçš„å­—å…¸
        """
        print(f"â±ï¸ é–‹å§‹åˆ†æè»Šæ‰‹ {driver} çš„åœˆé€Ÿè¡¨ç¾...")
        
        try:
            # ç”Ÿæˆç·©å­˜éµ
            cache_key = f"laptime_analysis_{self.year}_{self.race}_{self.session}_{driver}"
            cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
            
            # æª¢æŸ¥ç·©å­˜
            if os.path.exists(cache_file):
                print("ğŸ“¦ å¾ç·©å­˜è¼‰å…¥åœˆé€Ÿåˆ†ææ•¸æ“š...")
                with open(cache_file, 'rb') as f:
                    cached_result = pickle.load(f)
                
                # é¡¯ç¤ºå°æ‡‰çš„ JSON æª”æ¡ˆè·¯å¾‘
                json_file = cache_file.replace('.pkl', '.json')
                if os.path.exists(json_file):
                    print(f"ğŸ“„ å°æ‡‰ JSON æª”æ¡ˆ: {json_file}")
                
                # é¡¯ç¤ºåœˆé€Ÿåˆ†æè¡¨æ ¼
                self._display_laptime_analysis_table(cached_result, driver)
                
                print("âœ… åœˆé€Ÿåˆ†æå®Œæˆ (ä½¿ç”¨ç·©å­˜)")
                return cached_result
            
            # è¼‰å…¥è³½äº‹æ•¸æ“š
            session_data = self.data_loader.get_loaded_data()
            
            if session_data is None:
                raise ValueError("ç„¡æ³•è¼‰å…¥è³½äº‹æ•¸æ“š")
            
            # å¾æ•¸æ“šå­—å…¸ä¸­ç²å–åœˆé€Ÿæ•¸æ“š
            if isinstance(session_data, dict):
                laps_data = session_data.get('laps')
                if laps_data is None:
                    raise ValueError("ç„¡æ³•æ‰¾åˆ°åœˆé€Ÿæ•¸æ“š")
            else:
                laps_data = getattr(session_data, 'laps', None)
                if laps_data is None:
                    raise ValueError("ç„¡æ³•æ‰¾åˆ°åœˆé€Ÿæ•¸æ“š")
            
            # ç²å–è»Šæ‰‹æ•¸æ“š
            driver_data = laps_data.pick_driver(driver)
            
            if driver_data.empty:
                raise ValueError(f"æ‰¾ä¸åˆ°è»Šæ‰‹ {driver} çš„æ•¸æ“š")
            
            # åˆ†æåœˆé€Ÿ
            result = {
                "success": True,
                "driver": driver,
                "year": self.year,
                "race": self.race,
                "session": self.session,
                "analysis_timestamp": datetime.now().isoformat(),
                "lap_time_analysis": {
                    "basic_statistics": self._calculate_basic_statistics(driver_data),
                    "fastest_laps": self._find_fastest_laps(driver_data),
                    "consistency_analysis": self._analyze_consistency(driver_data),
                    "sector_analysis": self._analyze_sectors(driver_data),
                    "performance_trends": self._analyze_performance_trends(driver_data),
                    "comparative_analysis": self._compare_with_session_average(driver_data, laps_data),
                    "pace_analysis": self._analyze_race_pace(driver_data)
                }
            }
            
            # ä¿å­˜åˆ°ç·©å­˜
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            
            # åŒæ™‚ä¿å­˜ç‚º JSON
            json_file = cache_file.replace('.pkl', '.json')
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ’¾ JSON åˆ†æçµæœå·²ä¿å­˜: {json_file}")
            
            # é¡¯ç¤ºåœˆé€Ÿåˆ†æè¡¨æ ¼
            self._display_laptime_analysis_table(result, driver)
            
            print("âœ… è»Šæ‰‹åœˆé€Ÿåˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            print(f"âŒ åœˆé€Ÿåˆ†æå¤±æ•—: {e}")
            return {
                "success": False,
                "error": str(e),
                "driver": driver,
                "analysis_timestamp": datetime.now().isoformat()
            }
    
    def _calculate_basic_statistics(self, driver_data) -> Dict[str, Any]:
        """è¨ˆç®—åŸºæœ¬åœˆé€Ÿçµ±è¨ˆ"""
        try:
            lap_times = driver_data['LapTime'].dropna()
            
            if lap_times.empty:
                return {"error": "ç„¡æœ‰æ•ˆåœˆé€Ÿæ•¸æ“š"}
            
            # è½‰æ›ç‚ºç§’æ•¸é€²è¡Œè¨ˆç®—
            times_seconds = [t.total_seconds() for t in lap_times]
            
            return {
                "total_laps": len(driver_data),
                "valid_laps": len(lap_times),
                "fastest_lap": min(times_seconds),
                "slowest_lap": max(times_seconds),
                "average_lap_time": np.mean(times_seconds),
                "median_lap_time": np.median(times_seconds),
                "lap_time_range": max(times_seconds) - min(times_seconds),
                "standard_deviation": np.std(times_seconds)
            }
        except Exception as e:
            return {"error": f"çµ±è¨ˆè¨ˆç®—å¤±æ•—: {e}"}
    
    def _find_fastest_laps(self, driver_data, top_n: int = 5) -> List[Dict[str, Any]]:
        """æ‰¾å‡ºæœ€å¿«çš„å¹¾åœˆ"""
        try:
            valid_laps = driver_data[driver_data['LapTime'].notna()].copy()
            
            if valid_laps.empty:
                return []
            
            # æŒ‰åœˆé€Ÿæ’åº
            valid_laps = valid_laps.sort_values('LapTime')
            fastest_laps = []
            
            for i, (_, lap) in enumerate(valid_laps.head(top_n).iterrows()):
                fastest_laps.append({
                    "rank": i + 1,
                    "lap_number": int(lap['LapNumber']),
                    "lap_time": lap['LapTime'].total_seconds(),
                    "compound": lap.get('Compound', 'Unknown'),
                    "tyre_life": lap.get('TyreLife', 'Unknown'),
                    "position": int(lap.get('Position', 0))
                })
            
            return fastest_laps
        except Exception as e:
            return [{"error": f"ç„¡æ³•åˆ†ææœ€å¿«åœˆ: {e}"}]
    
    def _analyze_consistency(self, driver_data) -> Dict[str, Any]:
        """åˆ†æåœˆé€Ÿä¸€è‡´æ€§"""
        try:
            lap_times = driver_data['LapTime'].dropna()
            
            if len(lap_times) < 3:
                return {"error": "æ•¸æ“šä¸è¶³ä»¥åˆ†æä¸€è‡´æ€§"}
            
            times_seconds = [t.total_seconds() for t in lap_times]
            mean_time = np.mean(times_seconds)
            std_dev = np.std(times_seconds)
            
            # è¨ˆç®—è®Šç•°ä¿‚æ•¸ (CV)
            coefficient_of_variation = (std_dev / mean_time) * 100
            
            # è¨ˆç®—åœ¨å¹³å‡æ™‚é–“Â±2ç§’å…§çš„åœˆæ•¸ç™¾åˆ†æ¯”
            within_2_seconds = sum(1 for t in times_seconds if abs(t - mean_time) <= 2.0)
            consistency_percentage = (within_2_seconds / len(times_seconds)) * 100
            
            return {
                "coefficient_of_variation": coefficient_of_variation,
                "consistency_percentage": consistency_percentage,
                "standard_deviation": std_dev,
                "outlier_laps": self._find_outlier_laps(driver_data, times_seconds, mean_time, std_dev)
            }
        except Exception as e:
            return {"error": f"ä¸€è‡´æ€§åˆ†æå¤±æ•—: {e}"}
    
    def _find_outlier_laps(self, driver_data, times_seconds: List[float], mean_time: float, std_dev: float) -> List[Dict[str, Any]]:
        """æ‰¾å‡ºç•°å¸¸åœˆé€Ÿ"""
        try:
            outliers = []
            threshold = 2 * std_dev  # 2å€‹æ¨™æº–å·®
            
            lap_times = driver_data['LapTime'].dropna()
            
            for i, (lap_time, (_, lap)) in enumerate(zip(times_seconds, lap_times.items())):
                if abs(lap_time - mean_time) > threshold:
                    lap_data = driver_data.loc[lap]
                    outliers.append({
                        "lap_number": int(lap_data['LapNumber']),
                        "lap_time": lap_time,
                        "deviation_from_mean": lap_time - mean_time,
                        "reason": "Significantly slower" if lap_time > mean_time else "Significantly faster"
                    })
            
            return outliers
        except:
            return []
    
    def _analyze_sectors(self, driver_data) -> Dict[str, Any]:
        """åˆ†æåˆ†æ®µæ™‚é–“"""
        try:
            sector_analysis = {}
            
            # æª¢æŸ¥æ˜¯å¦æœ‰åˆ†æ®µæ™‚é–“æ•¸æ“š
            sector_columns = ['Sector1Time', 'Sector2Time', 'Sector3Time']
            available_sectors = [col for col in sector_columns if col in driver_data.columns]
            
            if not available_sectors:
                return {"error": "ç„¡åˆ†æ®µæ™‚é–“æ•¸æ“š"}
            
            for sector_col in available_sectors:
                sector_data = driver_data[sector_col].dropna()
                
                if not sector_data.empty:
                    sector_times = [t.total_seconds() for t in sector_data]
                    sector_num = sector_col.replace('Sector', '').replace('Time', '')
                    
                    sector_analysis[f"sector_{sector_num}"] = {
                        "fastest_time": min(sector_times),
                        "average_time": np.mean(sector_times),
                        "consistency": np.std(sector_times),
                        "improvement_potential": max(sector_times) - min(sector_times)
                    }
            
            return sector_analysis
        except Exception as e:
            return {"error": f"åˆ†æ®µåˆ†æå¤±æ•—: {e}"}
    
    def _analyze_performance_trends(self, driver_data) -> Dict[str, Any]:
        """åˆ†æè¡¨ç¾è¶¨å‹¢"""
        try:
            lap_times = driver_data['LapTime'].dropna()
            
            if len(lap_times) < 5:
                return {"error": "æ•¸æ“šä¸è¶³ä»¥åˆ†æè¶¨å‹¢"}
            
            times_seconds = [t.total_seconds() for t in lap_times]
            lap_numbers = range(1, len(times_seconds) + 1)
            
            # è¨ˆç®—è¶¨å‹¢ç·šæ–œç‡
            trend_slope = np.polyfit(lap_numbers, times_seconds, 1)[0]
            
            # åˆ†æå‰åŠæ®µ vs å¾ŒåŠæ®µ
            mid_point = len(times_seconds) // 2
            first_half_avg = np.mean(times_seconds[:mid_point])
            second_half_avg = np.mean(times_seconds[mid_point:])
            
            return {
                "trend_slope": trend_slope,
                "trending": "Improving" if trend_slope < -0.1 else "Degrading" if trend_slope > 0.1 else "Stable",
                "first_half_average": first_half_avg,
                "second_half_average": second_half_avg,
                "race_degradation": second_half_avg - first_half_avg,
                "strongest_stint": self._find_strongest_stint(times_seconds)
            }
        except Exception as e:
            return {"error": f"è¶¨å‹¢åˆ†æå¤±æ•—: {e}"}
    
    def _find_strongest_stint(self, times_seconds: List[float]) -> Dict[str, Any]:
        """æ‰¾å‡ºè¡¨ç¾æœ€å¥½çš„é€£çºŒæ®µè½"""
        try:
            if len(times_seconds) < 5:
                return {"error": "æ•¸æ“šä¸è¶³"}
            
            stint_length = 5  # åˆ†æ5åœˆçš„é€£çºŒæ®µè½
            best_stint = None
            best_average = float('inf')
            
            for i in range(len(times_seconds) - stint_length + 1):
                stint_times = times_seconds[i:i + stint_length]
                stint_average = np.mean(stint_times)
                
                if stint_average < best_average:
                    best_average = stint_average
                    best_stint = {
                        "start_lap": i + 1,
                        "end_lap": i + stint_length,
                        "average_time": stint_average,
                        "consistency": np.std(stint_times)
                    }
            
            return best_stint or {"error": "ç„¡æ³•æ‰¾åˆ°æœ€ä½³æ®µè½"}
        except:
            return {"error": "åˆ†æå¤±æ•—"}
    
    def _compare_with_session_average(self, driver_data, laps_data) -> Dict[str, Any]:
        """èˆ‡å…¨å ´å¹³å‡æ¯”è¼ƒ"""
        try:
            driver_times = driver_data['LapTime'].dropna()
            session_times = laps_data['LapTime'].dropna()
            
            if driver_times.empty or session_times.empty:
                return {"error": "ç„¡è¶³å¤ æ•¸æ“šé€²è¡Œæ¯”è¼ƒ"}
            
            driver_avg = np.mean([t.total_seconds() for t in driver_times])
            session_avg = np.mean([t.total_seconds() for t in session_times])
            
            return {
                "driver_average": driver_avg,
                "session_average": session_avg,
                "gap_to_average": driver_avg - session_avg,
                "relative_performance": "Above Average" if driver_avg < session_avg else "Below Average",
                "percentile_rank": self._calculate_percentile_rank(driver_avg, session_times)
            }
        except Exception as e:
            return {"error": f"æ¯”è¼ƒåˆ†æå¤±æ•—: {e}"}
    
    def _calculate_percentile_rank(self, driver_avg: float, session_times) -> float:
        """è¨ˆç®—è»Šæ‰‹åœ¨å…¨å ´çš„ç™¾åˆ†ä½æ’å"""
        try:
            all_times = [t.total_seconds() for t in session_times]
            better_count = sum(1 for t in all_times if t < driver_avg)
            return (better_count / len(all_times)) * 100
        except:
            return 0.0
    
    def _analyze_race_pace(self, driver_data) -> Dict[str, Any]:
        """åˆ†ææ¯”è³½ç¯€å¥"""
        try:
            # æ’é™¤å‰3åœˆå’Œæœ€å¾Œ2åœˆä»¥ç²å¾—ç´”æ¯”è³½ç¯€å¥
            race_laps = driver_data.iloc[3:-2] if len(driver_data) > 5 else driver_data
            race_times = race_laps['LapTime'].dropna()
            
            if race_times.empty:
                return {"error": "ç„¡è¶³å¤ æ¯”è³½ç¯€å¥æ•¸æ“š"}
            
            times_seconds = [t.total_seconds() for t in race_times]
            
            return {
                "pure_race_pace": np.mean(times_seconds),
                "race_pace_consistency": np.std(times_seconds),
                "pace_rating": self._rate_pace_consistency(np.std(times_seconds)),
                "fuel_corrected_pace": self._estimate_fuel_corrected_pace(times_seconds)
            }
        except Exception as e:
            return {"error": f"æ¯”è³½ç¯€å¥åˆ†æå¤±æ•—: {e}"}
    
    def _rate_pace_consistency(self, std_dev: float) -> str:
        """è©•ä¼°ç¯€å¥ä¸€è‡´æ€§ç­‰ç´š"""
        if std_dev < 0.5:
            return "Excellent"
        elif std_dev < 1.0:
            return "Good"
        elif std_dev < 1.5:
            return "Average"
        elif std_dev < 2.0:
            return "Below Average"
        else:
            return "Poor"
    
    def _estimate_fuel_corrected_pace(self, times_seconds: List[float]) -> Optional[float]:
        """ä¼°ç®—ç‡ƒæ²¹ä¿®æ­£å¾Œçš„ç¯€å¥ (ç°¡åŒ–ç‰ˆ)"""
        try:
            if len(times_seconds) < 10:
                return None
            
            # ç°¡åŒ–çš„ç‡ƒæ²¹ä¿®æ­£ï¼šå‡è¨­æ¯åœˆç¯€çœ0.05ç§’ç‡ƒæ²¹é‡é‡
            fuel_correction_per_lap = 0.05
            corrected_times = []
            
            for i, lap_time in enumerate(times_seconds):
                fuel_correction = i * fuel_correction_per_lap
                corrected_times.append(lap_time - fuel_correction)
            
            return np.mean(corrected_times)
        except:
            return None
    
    def _display_laptime_analysis_table(self, result: Dict[str, Any], driver: str):
        """é¡¯ç¤ºåœˆé€Ÿåˆ†æçµæœè¡¨æ ¼"""
        try:
            laptime_data = result.get('lap_time_analysis', {})
            
            print(f"\nâ±ï¸ è»Šæ‰‹ {driver} åœˆé€Ÿåˆ†æçµæœ")
            print("=" * 80)
            
            # åŸºæœ¬çµ±è¨ˆè¡¨æ ¼
            basic_stats = laptime_data.get('basic_statistics', {})
            if basic_stats and not basic_stats.get('error'):
                stats_table = PrettyTable()
                stats_table.field_names = ["çµ±è¨ˆé …ç›®", "åœˆé€Ÿ", "èªªæ˜"]
                stats_table.align["çµ±è¨ˆé …ç›®"] = "l"
                stats_table.align["èªªæ˜"] = "l"
                
                fastest = basic_stats.get('fastest_lap', 0)
                slowest = basic_stats.get('slowest_lap', 0)
                average = basic_stats.get('average_lap_time', 0)
                median = basic_stats.get('median_lap_time', 0)
                std_dev = basic_stats.get('standard_deviation', 0)
                total_laps = basic_stats.get('total_laps', 0)
                valid_laps = basic_stats.get('valid_laps', 0)
                
                def format_time(seconds):
                    if seconds > 0:
                        return f"{int(seconds//60)}:{seconds%60:06.3f}"
                    return "N/A"
                
                stats_table.add_row(["æœ€å¿«åœˆé€Ÿ", format_time(fastest), "å–®åœˆæœ€å¿«æ™‚é–“"])
                stats_table.add_row(["æœ€æ…¢åœˆé€Ÿ", format_time(slowest), "å–®åœˆæœ€æ…¢æ™‚é–“"])
                stats_table.add_row(["å¹³å‡åœˆé€Ÿ", format_time(average), "æ‰€æœ‰æœ‰æ•ˆåœˆé€Ÿçš„å¹³å‡"])
                stats_table.add_row(["ä¸­ä½æ•¸åœˆé€Ÿ", format_time(median), "åœˆé€Ÿåˆ†å¸ƒçš„ä¸­ä½æ•¸"])
                stats_table.add_row(["æ¨™æº–å·®", f"{std_dev:.3f}s", "åœˆé€Ÿä¸€è‡´æ€§æŒ‡æ¨™"])
                stats_table.add_row(["ç¸½åœˆæ•¸", f"{total_laps} åœˆ", "å®Œæˆçš„ç¸½åœˆæ•¸"])
                stats_table.add_row(["æœ‰æ•ˆåœˆæ•¸", f"{valid_laps} åœˆ", f"æœ‰æ•ˆåœˆé€Ÿæ•¸é‡ ({valid_laps/total_laps*100:.1f}%)" if total_laps > 0 else "æœ‰æ•ˆåœˆé€Ÿæ•¸é‡"])
                
                print(f"\nğŸ“Š åŸºæœ¬åœˆé€Ÿçµ±è¨ˆ:")
                print(stats_table)
            
            # æœ€å¿«åœˆæ•¸è¡¨æ ¼
            fastest_laps = laptime_data.get('fastest_laps', [])
            if fastest_laps and not any(lap.get('error') for lap in fastest_laps):
                fastest_table = PrettyTable()
                fastest_table.field_names = ["æ’å", "åœˆæ•¸", "åœˆé€Ÿ", "è¼ªèƒé…æ–¹", "è¼ªèƒå£½å‘½", "ä½ç½®"]
                fastest_table.align["è¼ªèƒé…æ–¹"] = "c"
                
                for lap in fastest_laps[:5]:  # é¡¯ç¤ºå‰5å¿«
                    rank = lap.get('rank', 0)
                    lap_num = lap.get('lap_number', 0)
                    lap_time = lap.get('lap_time', 0)
                    compound = lap.get('compound', 'Unknown')
                    tyre_life = lap.get('tyre_life', 'Unknown')
                    position = lap.get('position', 0)
                    
                    time_str = f"{int(lap_time//60)}:{lap_time%60:06.3f}" if lap_time > 0 else "N/A"
                    
                    fastest_table.add_row([f"ç¬¬ {rank} å¿«", f"ç¬¬ {lap_num} åœˆ", time_str, compound, f"{tyre_life} åœˆ" if isinstance(tyre_life, (int, float)) else tyre_life, f"P{position}"])
                
                print(f"\nğŸ† æœ€å¿«åœˆé€Ÿæ’è¡Œ:")
                print(fastest_table)
            
            # ä¸€è‡´æ€§åˆ†æè¡¨æ ¼
            consistency = laptime_data.get('consistency_analysis', {})
            if consistency and not consistency.get('error'):
                consistency_table = PrettyTable()
                consistency_table.field_names = ["ä¸€è‡´æ€§æŒ‡æ¨™", "æ•¸å€¼", "è©•ä¼°", "èªªæ˜"]
                consistency_table.align["ä¸€è‡´æ€§æŒ‡æ¨™"] = "l"
                consistency_table.align["èªªæ˜"] = "l"
                
                cv = consistency.get('coefficient_of_variation', 0)
                consistency_pct = consistency.get('consistency_percentage', 0)
                std_dev = consistency.get('standard_deviation', 0)
                outliers = consistency.get('outlier_laps', [])
                
                cv_rating = "å„ªç§€" if cv < 1.0 else "è‰¯å¥½" if cv < 2.0 else "ä¸€èˆ¬" if cv < 3.0 else "éœ€æ”¹å–„"
                consistency_rating = "å„ªç§€" if consistency_pct > 90 else "è‰¯å¥½" if consistency_pct > 80 else "ä¸€èˆ¬" if consistency_pct > 70 else "éœ€æ”¹å–„"
                
                consistency_table.add_row(["è®Šç•°ä¿‚æ•¸", f"{cv:.2f}%", cv_rating, "è¶Šä½è¶Šä¸€è‡´"])
                consistency_table.add_row(["ä¸€è‡´æ€§ç™¾åˆ†æ¯”", f"{consistency_pct:.1f}%", consistency_rating, "åœ¨Â±2ç§’å…§çš„åœˆæ•¸ç™¾åˆ†æ¯”"])
                consistency_table.add_row(["æ¨™æº–å·®", f"{std_dev:.3f}s", "æ¨™æº–", "åœˆé€Ÿé›¢æ•£ç¨‹åº¦"])
                consistency_table.add_row(["ç•°å¸¸åœˆæ•¸", f"{len(outliers)} åœˆ", "åµæ¸¬", "æ˜é¡¯åé›¢å¹³å‡çš„åœˆæ•¸"])
                
                print(f"\nğŸ“ˆ åœˆé€Ÿä¸€è‡´æ€§åˆ†æ:")
                print(consistency_table)
            
            # è¡¨ç¾è¶¨å‹¢è¡¨æ ¼
            trends = laptime_data.get('performance_trends', {})
            if trends and not trends.get('error'):
                trends_table = PrettyTable()
                trends_table.field_names = ["è¶¨å‹¢é …ç›®", "æ•¸å€¼", "è©•ä¼°", "èªªæ˜"]
                trends_table.align["è¶¨å‹¢é …ç›®"] = "l"
                trends_table.align["èªªæ˜"] = "l"
                
                trend_slope = trends.get('trend_slope', 0)
                trending = trends.get('trending', 'Unknown')
                first_half = trends.get('first_half_average', 0)
                second_half = trends.get('second_half_average', 0)
                degradation = trends.get('race_degradation', 0)
                
                def format_time_short(seconds):
                    if seconds > 0:
                        return f"{int(seconds//60)}:{seconds%60:06.3f}"
                    return "N/A"
                
                trend_desc = "è¡¨ç¾æå‡" if trend_slope < -0.1 else "è¡¨ç¾ä¸‹é™" if trend_slope > 0.1 else "è¡¨ç¾ç©©å®š"
                degradation_desc = "å‰åŠæ®µè¼ƒå¿«" if degradation < 0 else "å¾ŒåŠæ®µè¼ƒå¿«" if degradation > 0 else "å‰å¾Œä¸€è‡´"
                
                trends_table.add_row(["è¶¨å‹¢æ–œç‡", f"{trend_slope:.4f}", trending, trend_desc])
                trends_table.add_row(["å‰åŠæ®µå¹³å‡", format_time_short(first_half), "åŸºæº–", "æ¯”è³½å‰åŠæ®µå¹³å‡åœˆé€Ÿ"])
                trends_table.add_row(["å¾ŒåŠæ®µå¹³å‡", format_time_short(second_half), "æ¯”è¼ƒ", "æ¯”è³½å¾ŒåŠæ®µå¹³å‡åœˆé€Ÿ"])
                trends_table.add_row(["åœˆé€Ÿè¡°é€€", f"{degradation:+.3f}s", degradation_desc, "å¾ŒåŠæ®µç›¸å°å‰åŠæ®µçš„è®ŠåŒ–"])
                
                print(f"\nğŸ“Š è¡¨ç¾è¶¨å‹¢åˆ†æ:")
                print(trends_table)
            
            # æ¯”è³½ç¯€å¥åˆ†æ
            pace_analysis = laptime_data.get('pace_analysis', {})
            if pace_analysis and not pace_analysis.get('error'):
                pace_table = PrettyTable()
                pace_table.field_names = ["ç¯€å¥æŒ‡æ¨™", "æ•¸å€¼", "è©•ç´š", "èªªæ˜"]
                pace_table.align["ç¯€å¥æŒ‡æ¨™"] = "l"
                pace_table.align["èªªæ˜"] = "l"
                
                race_pace = pace_analysis.get('pure_race_pace', 0)
                pace_consistency = pace_analysis.get('race_pace_consistency', 0)
                pace_rating = pace_analysis.get('pace_rating', 'Unknown')
                fuel_corrected = pace_analysis.get('fuel_corrected_pace')
                
                def format_time_short(seconds):
                    if seconds > 0:
                        return f"{int(seconds//60)}:{seconds%60:06.3f}"
                    return "N/A"
                
                pace_table.add_row(["ç´”æ¯”è³½ç¯€å¥", format_time_short(race_pace), "åŸºæº–", "æ’é™¤é–‹é ­å’Œçµå°¾åœˆçš„å¹³å‡åœˆé€Ÿ"])
                pace_table.add_row(["ç¯€å¥ä¸€è‡´æ€§", f"{pace_consistency:.3f}s", pace_rating, "æ¯”è³½ç¯€å¥çš„ç©©å®šç¨‹åº¦"])
                
                if fuel_corrected:
                    pace_table.add_row(["ç‡ƒæ²¹ä¿®æ­£ç¯€å¥", format_time_short(fuel_corrected), "ä¼°ç®—", "è€ƒæ…®ç‡ƒæ²¹é‡é‡å¾Œçš„ç†è«–ç¯€å¥"])
                
                print(f"\nğŸƒ æ¯”è³½ç¯€å¥åˆ†æ:")
                print(pace_table)
            
            print("=" * 80)
            
        except Exception as e:
            print(f"âŒ é¡¯ç¤ºåœˆé€Ÿåˆ†æè¡¨æ ¼å¤±æ•—: {e}")
            # é¡¯ç¤ºåŸºæœ¬ä¿¡æ¯ä½œç‚ºå‚™ç”¨
            print(f"\nâ±ï¸ è»Šæ‰‹ {driver} åœˆé€Ÿåˆ†æçµæœ (ç°¡åŒ–ç‰ˆ)")
            print(f"åˆ†ææ™‚é–“: {result.get('analysis_timestamp', 'Unknown')}")
            print(f"åˆ†æç‹€æ…‹: {'æˆåŠŸ' if result.get('success') else 'å¤±æ•—'}")

    def analyze_fastest_lap(self, driver: str, **kwargs) -> Dict[str, Any]:
        """Function 26: åˆ†æè»Šæ‰‹æœ€é€Ÿåœˆé€Ÿè¡¨ç¾
        
        Args:
            driver: è»Šæ‰‹ä»£ç¢¼ (å¦‚ 'VER', 'LEC')
            
        Returns:
            Dict: åŒ…å«æœ€é€Ÿåœˆåˆ†æçµæœçš„å­—å…¸
        """
        print(f"âš¡ é–‹å§‹åˆ†æè»Šæ‰‹ {driver} çš„æœ€é€Ÿåœˆè¡¨ç¾...")
        
        try:
            # ç”Ÿæˆç·©å­˜éµ
            cache_key = f"fastest_lap_analysis_{self.year}_{self.race}_{self.session}_{driver}"
            cache_file = os.path.join(self.cache_dir, f"{cache_key}.pkl")
            
            # æª¢æŸ¥ç·©å­˜
            if os.path.exists(cache_file):
                print("ğŸ“¦ å¾ç·©å­˜è¼‰å…¥æœ€é€Ÿåœˆåˆ†ææ•¸æ“š...")
                with open(cache_file, 'rb') as f:
                    cached_result = pickle.load(f)
                
                # é¡¯ç¤ºçµæœ
                self._display_fastest_lap_analysis(driver, cached_result)
                return cached_result
            
            # ç²å–æ•¸æ“š
            data = self.data_loader.get_loaded_data()
            if not data:
                return {"error": "ç„¡æ³•ç²å–æ•¸æ“š"}
            
            laps = data['laps']
            driver_data = laps[laps['Driver'] == driver].copy()
            
            if driver_data.empty:
                return {"error": f"è»Šæ‰‹ {driver} ç„¡æ•¸æ“š"}
            
            # åŸ·è¡Œæœ€é€Ÿåœˆåˆ†æ
            result = self._analyze_fastest_lap_performance(driver, driver_data)
            
            # ä¿å­˜ç·©å­˜
            with open(cache_file, 'wb') as f:
                pickle.dump(result, f)
            
            # ä¿å­˜JSON
            json_file = f"fastest_lap_analysis_{self.year}_{self.race}_{self.session}_{driver}.json"
            json_path = os.path.join("json", json_file)
            os.makedirs("json", exist_ok=True)
            
            with open(json_path, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ“„ JSON åˆ†æå ±å‘Šå·²ä¿å­˜: {json_path}")
            
            # é¡¯ç¤ºçµæœ
            self._display_fastest_lap_analysis(driver, result)
            
            return result
            
        except Exception as e:
            print(f"âŒ æœ€é€Ÿåœˆåˆ†æå¤±æ•—: {e}")
            return {"error": str(e)}
    
    def _analyze_fastest_lap_performance(self, driver: str, driver_data) -> Dict[str, Any]:
        """åˆ†ææœ€é€Ÿåœˆè¡¨ç¾"""
        try:
            valid_laps = driver_data[driver_data['LapTime'].notna()].copy()
            
            if valid_laps.empty:
                return {"error": "ç„¡æœ‰æ•ˆåœˆé€Ÿæ•¸æ“š"}
            
            # æ‰¾å‡ºæœ€å¿«åœˆ
            fastest_lap_idx = valid_laps['LapTime'].idxmin()
            fastest_lap = valid_laps.loc[fastest_lap_idx]
            
            # åŸºæœ¬ä¿¡æ¯
            fastest_time = fastest_lap['LapTime'].total_seconds()
            lap_number = int(fastest_lap['LapNumber'])
            
            # è¼ªèƒä¿¡æ¯
            compound = fastest_lap.get('Compound', 'Unknown')
            tyre_life = fastest_lap.get('TyreLife', 'Unknown')
            
            # åˆ†æ®µæ™‚é–“
            sector_times = {
                'sector_1': fastest_lap.get('Sector1Time'),
                'sector_2': fastest_lap.get('Sector2Time'),
                'sector_3': fastest_lap.get('Sector3Time')
            }
            
            # ä½ç½®ä¿¡æ¯
            position = fastest_lap.get('Position', 'Unknown')
            
            # èˆ‡å¹³å‡åœˆé€Ÿæ¯”è¼ƒ
            avg_lap_time = valid_laps['LapTime'].mean().total_seconds()
            improvement = avg_lap_time - fastest_time
            
            result = {
                "driver": driver,
                "fastest_lap": {
                    "lap_number": lap_number,
                    "lap_time_seconds": fastest_time,
                    "lap_time_formatted": self._format_time_seconds(fastest_time),
                    "compound": compound,
                    "tyre_life": tyre_life,
                    "position": position
                },
                "sector_times": {
                    "sector_1": self._format_time_delta(sector_times['sector_1']),
                    "sector_2": self._format_time_delta(sector_times['sector_2']),
                    "sector_3": self._format_time_delta(sector_times['sector_3'])
                },
                "comparison": {
                    "average_lap_time": self._format_time_seconds(avg_lap_time),
                    "improvement_from_average": self._format_time_seconds(improvement),
                    "percentage_improvement": (improvement / avg_lap_time) * 100
                },
                "session_stats": {
                    "total_laps": len(driver_data),
                    "valid_laps": len(valid_laps),
                    "fastest_lap_rank": self._get_fastest_lap_rank(driver_data, fastest_time)
                },
                "analysis_timestamp": datetime.now().isoformat(),
                "success": True
            }
            
            return result
            
        except Exception as e:
            return {"error": f"æœ€é€Ÿåœˆåˆ†æå¤±æ•—: {e}", "success": False}
    
    def _get_fastest_lap_rank(self, driver_data, fastest_time: float) -> int:
        """ç²å–æœ€å¿«åœˆåœ¨æ‰€æœ‰åœˆä¸­çš„æ’å"""
        try:
            valid_times = driver_data['LapTime'].dropna()
            times_seconds = [t.total_seconds() for t in valid_times]
            times_seconds.sort()
            
            rank = times_seconds.index(fastest_time) + 1
            return rank
        except:
            return 1
    
    def _format_time_seconds(self, seconds: float) -> str:
        """æ ¼å¼åŒ–ç§’æ•¸ç‚ºæ™‚é–“æ ¼å¼"""
        if pd.isna(seconds):
            return "N/A"
        
        minutes = int(seconds // 60)
        secs = seconds % 60
        return f"{minutes}:{secs:06.3f}"
    
    def _format_time_delta(self, time_delta) -> str:
        """æ ¼å¼åŒ–æ™‚é–“å·®"""
        if pd.isna(time_delta) or time_delta is None:
            return "N/A"
        
        if hasattr(time_delta, 'total_seconds'):
            seconds = time_delta.total_seconds()
            return f"{seconds:.3f}s"
        
        return str(time_delta)
    
    def _display_fastest_lap_analysis(self, driver: str, result: Dict[str, Any]):
        """é¡¯ç¤ºæœ€é€Ÿåœˆåˆ†æçµæœ"""
        try:
            if result.get('error'):
                print(f"âŒ åˆ†æéŒ¯èª¤: {result['error']}")
                return
            
            print(f"\nâš¡ {driver} æœ€é€Ÿåœˆåˆ†æçµæœ:")
            print("=" * 60)
            
            fastest_lap = result.get('fastest_lap', {})
            
            # åŸºæœ¬ä¿¡æ¯è¡¨æ ¼
            info_table = PrettyTable()
            info_table.field_names = ["é …ç›®", "æ•¸å€¼"]
            info_table.align = "l"
            
            info_table.add_row(["ğŸ æœ€å¿«åœˆåœˆæ•¸", f"ç¬¬ {fastest_lap.get('lap_number', 'N/A')} åœˆ"])
            info_table.add_row(["â±ï¸ æœ€å¿«åœˆæ™‚é–“", fastest_lap.get('lap_time_formatted', 'N/A')])
            info_table.add_row(["ğŸ› ä½¿ç”¨è¼ªèƒ", fastest_lap.get('compound', 'N/A')])
            info_table.add_row(["ğŸ”„ è¼ªèƒå£½å‘½", f"{fastest_lap.get('tyre_life', 'N/A')} åœˆ"])
            info_table.add_row(["ğŸ“ ç•¶æ™‚ä½ç½®", f"P{fastest_lap.get('position', 'N/A')}"])
            
            print(info_table)
            
            # åˆ†æ®µæ™‚é–“è¡¨æ ¼
            sector_times = result.get('sector_times', {})
            if any(sector_times.values()):
                print("\nğŸ åˆ†æ®µæ™‚é–“:")
                sector_table = PrettyTable()
                sector_table.field_names = ["åˆ†æ®µ", "æ™‚é–“"]
                sector_table.align = "l"
                
                sector_table.add_row(["Sector 1", sector_times.get('sector_1', 'N/A')])
                sector_table.add_row(["Sector 2", sector_times.get('sector_2', 'N/A')])
                sector_table.add_row(["Sector 3", sector_times.get('sector_3', 'N/A')])
                
                print(sector_table)
            
            # æ¯”è¼ƒåˆ†æ
            comparison = result.get('comparison', {})
            if comparison:
                print("\nğŸ“Š è¡¨ç¾æ¯”è¼ƒ:")
                comp_table = PrettyTable()
                comp_table.field_names = ["æ¯”è¼ƒé …ç›®", "æ•¸å€¼"]
                comp_table.align = "l"
                
                comp_table.add_row(["å¹³å‡åœˆé€Ÿ", comparison.get('average_lap_time', 'N/A')])
                comp_table.add_row(["è¼ƒå¹³å‡å¿«", comparison.get('improvement_from_average', 'N/A')])
                
                improvement_pct = comparison.get('percentage_improvement', 0)
                if improvement_pct > 0:
                    comp_table.add_row(["æ”¹å–„å¹…åº¦", f"{improvement_pct:.2f}%"])
                
                print(comp_table)
            
            print("=" * 60)
            print("âœ… æœ€é€Ÿåœˆåˆ†æå®Œæˆï¼")
            
        except Exception as e:
            print(f"âŒ é¡¯ç¤ºæœ€é€Ÿåœˆåˆ†æå¤±æ•—: {e}")
            print(f"è»Šæ‰‹ {driver} æœ€é€Ÿåœˆåˆ†æçµæœ (ç°¡åŒ–ç‰ˆ)")
            print(f"åˆ†æç‹€æ…‹: {'æˆåŠŸ' if result.get('success') else 'å¤±æ•—'}")

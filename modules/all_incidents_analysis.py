#!/usr/bin/env python3
"""
F1 æ‰€æœ‰äº‹ä»¶è©³ç´°åˆ—è¡¨æ¨¡çµ„ (åŠŸèƒ½ 4.5)
ä½œè€…: F1 Analysis Team
ç‰ˆæœ¬: 1.0

å°ˆé–€è™•ç†æ‰€æœ‰äº‹ä»¶è©³ç´°åˆ—è¡¨åˆ†æï¼ŒåŒ…æ‹¬ï¼š
- å®Œæ•´äº‹ä»¶æ™‚é–“è»¸
- äº‹ä»¶åˆ†é¡å’Œçµ±è¨ˆ
- è©³ç´°äº‹ä»¶ä¿¡æ¯è¡¨æ ¼
- æ™‚åºåˆ†æ
"""

import os
import sys
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
from prettytable import PrettyTable
import re


def clean_for_json(obj):
    """æ¸…ç†æ•¸æ“šä»¥ä¾¿JSONåºåˆ—åŒ–"""
    if obj is None:
        return None
    elif isinstance(obj, (str, int, float, bool)):
        return obj
    elif hasattr(obj, 'isoformat'):  # datetime objects
        return obj.isoformat()
    elif isinstance(obj, (list, tuple)):
        return [clean_for_json(item) for item in obj]
    elif isinstance(obj, dict):
        return {key: clean_for_json(value) for key, value in obj.items()}
    else:
        return str(obj)


def analyze_all_incidents_data(data_loader):
    """åˆ†ææ‰€æœ‰äº‹ä»¶æ•¸æ“š"""
    try:
        if not data_loader or not hasattr(data_loader, 'loaded_data') or not data_loader.loaded_data:
            print("[ERROR] ç„¡æ³•ç²å–å·²è¼‰å…¥çš„æ•¸æ“š")
            return None
            
        loaded_data = data_loader.loaded_data
        
        # æå–åŸºæœ¬æœƒè©±ä¿¡æ¯
        session_info = {
            "year": getattr(loaded_data.get('session'), 'year', 'Unknown'),
            "race": getattr(loaded_data.get('session'), 'event_name', 'Unknown'),
            "session_type": getattr(loaded_data.get('session'), 'session_type', 'R'),
            "track_name": getattr(loaded_data.get('session'), 'event', {}).get('EventName', 'Unknown'),
            "date": str(getattr(loaded_data.get('session'), 'date', 'Unknown'))
        }
        
        # æå–æ‰€æœ‰è³½äº‹äº‹ä»¶
        race_control_messages = extract_race_control_messages(loaded_data)
        all_incidents = process_all_incidents(race_control_messages)
        timeline_analysis = create_timeline_analysis(all_incidents)
        
        return {
            "session_info": session_info,
            "all_incidents": all_incidents,
            "timeline_analysis": timeline_analysis,
            "total_incidents": len(all_incidents),
            "incident_statistics": generate_incident_statistics(all_incidents)
        }
        
    except Exception as e:
        print(f"[ERROR] åˆ†ææ‰€æœ‰äº‹ä»¶æ•¸æ“šæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return None


def extract_race_control_messages(loaded_data):
    """æå–è³½äº‹æ§åˆ¶æ¶ˆæ¯"""
    try:
        session = loaded_data.get('session')
        if not session:
            return []
            
        # å˜—è©¦ç²å–è³½äº‹æ§åˆ¶æ¶ˆæ¯
        if hasattr(session, 'race_control_messages'):
            messages_df = session.race_control_messages
            if messages_df is not None and not messages_df.empty:
                return messages_df.to_dict('records')
        
        return []
        
    except Exception as e:
        print(f"[WARNING] æå–è³½äº‹æ§åˆ¶æ¶ˆæ¯å¤±æ•—: {e}")
        return []


def process_all_incidents(race_control_messages):
    """è™•ç†æ‰€æœ‰äº‹ä»¶"""
    all_incidents = []
    
    for i, message in enumerate(race_control_messages):
        try:
            message_text = message.get('Message', '')
            lap_number = message.get('Lap', 'Unknown')
            timestamp = message.get('Time', 'Unknown')
            
            # æå–æ¶‰åŠçš„è»Šæ‰‹
            involved_drivers = extract_involved_drivers(message_text)
            
            incident = {
                "incident_id": i + 1,
                "timestamp": str(timestamp),
                "lap": lap_number,
                "message": message_text,
                "category": categorize_incident(message_text),
                "severity": assess_incident_severity(message_text),
                "involved_drivers": involved_drivers,
                "driver_count": len(involved_drivers),
                "flags": extract_flags(message_text),
                "penalties": extract_penalties(message_text),
                "track_position": extract_track_position(message_text)
            }
            
            all_incidents.append(incident)
            
        except Exception as e:
            print(f"[WARNING] è™•ç†äº‹ä»¶ {i+1} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            continue
    
    return all_incidents


def extract_involved_drivers(message_text):
    """æå–æ¶‰åŠçš„è»Šæ‰‹"""
    drivers = []
    
    # æ¨™æº–æ ¼å¼: CAR 1 (VER)
    car_matches = re.findall(r'CAR \d+ \(([A-Z]{3})\)', message_text.upper())
    drivers.extend(car_matches)
    
    # å¤šè»Šæ‰‹æ ¼å¼: CARS 1 (VER) AND 44 (HAM)
    multi_car_matches = re.findall(r'\(([A-Z]{3})\)', message_text.upper())
    for driver in multi_car_matches:
        if driver not in drivers:
            drivers.append(driver)
    
    return drivers


def categorize_incident(message_text):
    """åˆ†é¡äº‹ä»¶"""
    message_upper = message_text.upper()
    
    if any(keyword in message_upper for keyword in ['SAFETY CAR', 'SC DEPLOYED', 'VSC']):
        return 'SAFETY_CAR'
    elif any(keyword in message_upper for keyword in ['YELLOW FLAG', 'YELLOW']):
        return 'YELLOW_FLAG'
    elif any(keyword in message_upper for keyword in ['RED FLAG', 'SESSION STOPPED']):
        return 'RED_FLAG'
    elif any(keyword in message_upper for keyword in ['DRS', 'DRAG REDUCTION']):
        return 'DRS_EVENT'
    elif 'TRACK LIMITS' in message_upper or 'TIME DELETED' in message_upper:
        return 'TRACK_LIMITS'
    elif any(keyword in message_upper for keyword in ['PENALTY', 'TIME PENALTY', 'GRID PENALTY']):
        return 'PENALTY'
    elif any(keyword in message_upper for keyword in ['CRASH', 'COLLISION', 'INCIDENT']):
        return 'INCIDENT'
    elif any(keyword in message_upper for keyword in ['PIT', 'PITSTOP']):
        return 'PIT_EVENT'
    elif any(keyword in message_upper for keyword in ['RAIN', 'WEATHER', 'WET']):
        return 'WEATHER'
    elif any(keyword in message_upper for keyword in ['START', 'FORMATION', 'GRID']):
        return 'RACE_START'
    elif any(keyword in message_upper for keyword in ['CHEQUERED', 'FINISH']):
        return 'RACE_END'
    else:
        return 'OTHER'


def assess_incident_severity(message_text):
    """è©•ä¼°äº‹ä»¶åš´é‡ç¨‹åº¦"""
    message_upper = message_text.upper()
    
    if any(keyword in message_upper for keyword in ['RED FLAG', 'CRASH', 'DANGEROUS', 'DISQUALIFIED']):
        return 'CRITICAL'
    elif any(keyword in message_upper for keyword in ['SAFETY CAR', 'YELLOW FLAG', 'PENALTY', 'COLLISION']):
        return 'HIGH'
    elif any(keyword in message_upper for keyword in ['INCIDENT', 'UNSAFE', 'WARNING']):
        return 'MEDIUM'
    elif any(keyword in message_upper for keyword in ['TRACK LIMITS', 'TIME DELETED', 'NOTED']):
        return 'LOW'
    else:
        return 'MINIMAL'


def extract_flags(message_text):
    """æå–æ——å¹Ÿä¿¡æ¯"""
    flags = []
    message_upper = message_text.upper()
    
    if 'YELLOW FLAG' in message_upper or 'YELLOW' in message_upper:
        flags.append('YELLOW')
    if 'RED FLAG' in message_upper:
        flags.append('RED')
    if 'GREEN FLAG' in message_upper or 'GREEN LIGHT' in message_upper:
        flags.append('GREEN')
    if 'BLUE FLAG' in message_upper:
        flags.append('BLUE')
    if 'CHEQUERED FLAG' in message_upper:
        flags.append('CHEQUERED')
    
    return flags


def extract_penalties(message_text):
    """æå–è™•ç½°ä¿¡æ¯"""
    penalties = []
    message_upper = message_text.upper()
    
    if 'TIME PENALTY' in message_upper:
        penalties.append('TIME_PENALTY')
    if 'GRID PENALTY' in message_upper:
        penalties.append('GRID_PENALTY')
    if 'DISQUALIFIED' in message_upper:
        penalties.append('DISQUALIFIED')
    if 'WARNING' in message_upper:
        penalties.append('WARNING')
    if 'TIME DELETED' in message_upper:
        penalties.append('TIME_DELETED')
    
    return penalties


def extract_track_position(message_text):
    """æå–è³½é“ä½ç½®ä¿¡æ¯"""
    message_upper = message_text.upper()
    
    # æå–å½é“ä¿¡æ¯
    turn_matches = re.findall(r'TURN (\d+)', message_upper)
    if turn_matches:
        return f"Turn {turn_matches[0]}"
    
    # æå–å…¶ä»–ä½ç½®ä¿¡æ¯
    if 'PIT ENTRY' in message_upper:
        return 'Pit Entry'
    elif 'PIT EXIT' in message_upper:
        return 'Pit Exit'
    elif 'START/FINISH' in message_upper:
        return 'Start/Finish Line'
    
    return 'Unknown'


def create_timeline_analysis(all_incidents):
    """å‰µå»ºæ™‚é–“è»¸åˆ†æ"""
    timeline = {
        "total_duration_laps": 0,
        "incidents_by_lap": {},
        "peak_activity_laps": [],
        "quiet_periods": [],
        "incident_frequency": {}
    }
    
    # æŒ‰åœˆæ•¸åˆ†çµ„äº‹ä»¶
    for incident in all_incidents:
        lap = incident.get('lap', 'Unknown')
        if lap != 'Unknown' and isinstance(lap, (int, float)):
            lap = int(lap)
            if lap not in timeline["incidents_by_lap"]:
                timeline["incidents_by_lap"][lap] = []
            timeline["incidents_by_lap"][lap].append(incident)
    
    # è¨ˆç®—ç¸½æŒçºŒåœˆæ•¸
    if timeline["incidents_by_lap"]:
        timeline["total_duration_laps"] = max(timeline["incidents_by_lap"].keys())
    
    # æ‰¾å‡ºé«˜æ´»å‹•åœˆæ•¸ï¼ˆäº‹ä»¶æ•¸ >= 3ï¼‰
    for lap, incidents in timeline["incidents_by_lap"].items():
        if len(incidents) >= 3:
            timeline["peak_activity_laps"].append({
                "lap": lap,
                "incident_count": len(incidents),
                "incidents": [inc["category"] for inc in incidents]
            })
    
    # è¨ˆç®—äº‹ä»¶é »ç‡
    category_count = {}
    for incident in all_incidents:
        category = incident.get('category', 'OTHER')
        category_count[category] = category_count.get(category, 0) + 1
    
    timeline["incident_frequency"] = category_count
    
    return timeline


def generate_incident_statistics(all_incidents):
    """ç”Ÿæˆäº‹ä»¶çµ±è¨ˆ"""
    stats = {
        "total_incidents": len(all_incidents),
        "by_category": {},
        "by_severity": {},
        "driver_involvement": {},
        "most_common_category": "",
        "most_severe_incidents": 0,
        "average_drivers_per_incident": 0
    }
    
    # æŒ‰é¡åˆ¥çµ±è¨ˆ
    for incident in all_incidents:
        category = incident.get('category', 'OTHER')
        severity = incident.get('severity', 'MINIMAL')
        involved_drivers = incident.get('involved_drivers', [])
        
        # é¡åˆ¥çµ±è¨ˆ
        stats["by_category"][category] = stats["by_category"].get(category, 0) + 1
        
        # åš´é‡ç¨‹åº¦çµ±è¨ˆ
        stats["by_severity"][severity] = stats["by_severity"].get(severity, 0) + 1
        
        # è»Šæ‰‹åƒèˆ‡çµ±è¨ˆ
        for driver in involved_drivers:
            stats["driver_involvement"][driver] = stats["driver_involvement"].get(driver, 0) + 1
    
    # æ‰¾å‡ºæœ€å¸¸è¦‹é¡åˆ¥
    if stats["by_category"]:
        stats["most_common_category"] = max(stats["by_category"].items(), key=lambda x: x[1])[0]
    
    # è¨ˆç®—åš´é‡äº‹ä»¶æ•¸
    stats["most_severe_incidents"] = stats["by_severity"].get("CRITICAL", 0) + stats["by_severity"].get("HIGH", 0)
    
    # è¨ˆç®—å¹³å‡è»Šæ‰‹åƒèˆ‡åº¦
    total_driver_involvement = sum(len(incident.get('involved_drivers', [])) for incident in all_incidents)
    stats["average_drivers_per_incident"] = round(total_driver_involvement / len(all_incidents), 2) if all_incidents else 0
    
    return stats


def display_all_incidents_table(analysis_result):
    """é¡¯ç¤ºæ‰€æœ‰äº‹ä»¶è¡¨æ ¼"""
    if not analysis_result:
        print("[ERROR] ç„¡åˆ†æçµæœå¯é¡¯ç¤º")
        return
    
    session_info = analysis_result.get("session_info", {})
    all_incidents = analysis_result.get("all_incidents", [])
    incident_statistics = analysis_result.get("incident_statistics", {})
    timeline_analysis = analysis_result.get("timeline_analysis", {})
    
    print(f"\n[LIST] æ‰€æœ‰äº‹ä»¶è©³ç´°åˆ—è¡¨ (åŠŸèƒ½ 4.5)")
    print("=" * 80)
    print(f"ğŸ“… è³½äº‹: {session_info.get('year')} {session_info.get('track_name')}")
    print(f"[FINISH] è³½æ®µ: {session_info.get('session_type')} | æ—¥æœŸ: {session_info.get('date')}")
    print(f"[INFO] ç¸½äº‹ä»¶æ•¸: {analysis_result.get('total_incidents', 0)}")
    print("=" * 80)
    
    # äº‹ä»¶çµ±è¨ˆæ‘˜è¦
    print(f"\n[INFO] äº‹ä»¶çµ±è¨ˆæ‘˜è¦:")
    print(f"ğŸ”´ åš´é‡äº‹ä»¶æ•¸: {incident_statistics.get('most_severe_incidents', 0)}")
    print(f"[STATS] æœ€å¸¸è¦‹äº‹ä»¶é¡å‹: {incident_statistics.get('most_common_category', 'N/A')}")
    print(f"ğŸ‘¥ å¹³å‡è»Šæ‰‹åƒèˆ‡åº¦: {incident_statistics.get('average_drivers_per_incident', 0)} è»Šæ‰‹/äº‹ä»¶")
    print(f"[FINISH] æ¯”è³½æŒçºŒåœˆæ•¸: {timeline_analysis.get('total_duration_laps', 0)} åœˆ")
    
    # é¡åˆ¥çµ±è¨ˆè¡¨æ ¼
    if incident_statistics.get('by_category'):
        category_table = PrettyTable()
        category_table.field_names = ["äº‹ä»¶é¡å‹", "æ•¸é‡", "ç™¾åˆ†æ¯”"]
        category_table.align = "l"
        
        total_incidents = incident_statistics.get('total_incidents', 1)
        sorted_categories = sorted(incident_statistics['by_category'].items(), key=lambda x: x[1], reverse=True)
        
        for category, count in sorted_categories:
            percentage = round((count / total_incidents) * 100, 1)
            category_table.add_row([
                category.replace('_', ' '),
                count,
                f"{percentage}%"
            ])
        
        print(f"\n[LIST] äº‹ä»¶é¡å‹çµ±è¨ˆ:")
        print(category_table)
    
    # è©³ç´°äº‹ä»¶åˆ—è¡¨ï¼ˆé¡¯ç¤ºå‰30å€‹ï¼‰
    if all_incidents:
        detail_table = PrettyTable()
        detail_table.field_names = ["ID", "åœˆæ•¸", "æ™‚é–“", "é¡å‹", "åš´é‡ç¨‹åº¦", "è»Šæ‰‹", "äº‹ä»¶æè¿°"]
        detail_table.align = "l"
        detail_table.max_width["äº‹ä»¶æè¿°"] = 40
        
        incidents_to_show = all_incidents[:30]  # åªé¡¯ç¤ºå‰30å€‹
        
        for incident in incidents_to_show:
            involved_drivers_str = ", ".join(incident.get('involved_drivers', []))[:15] + "..." if len(", ".join(incident.get('involved_drivers', []))) > 15 else ", ".join(incident.get('involved_drivers', []))
            
            detail_table.add_row([
                incident.get('incident_id', 'N/A'),
                incident.get('lap', 'N/A'),
                str(incident.get('timestamp', 'Unknown'))[:8] + "..." if len(str(incident.get('timestamp', 'Unknown'))) > 8 else str(incident.get('timestamp', 'Unknown')),
                incident.get('category', 'OTHER').replace('_', ' ')[:12],
                incident.get('severity', 'MINIMAL')[:8],
                involved_drivers_str,
                incident.get('message', '')[:40] + "..." if len(incident.get('message', '')) > 40 else incident.get('message', '')
            ])
        
        print(f"\n[NOTE] è©³ç´°äº‹ä»¶åˆ—è¡¨ (é¡¯ç¤ºå‰30é …ï¼Œå…±{len(all_incidents)}é …):")
        print(detail_table)
        
        if len(all_incidents) > 30:
            print(f"... é‚„æœ‰ {len(all_incidents) - 30} é …äº‹ä»¶ (è«‹æŸ¥çœ‹JSONæ–‡ä»¶ç²å–å®Œæ•´åˆ—è¡¨)")
    
    # é«˜æ´»å‹•åœˆæ•¸åˆ†æ
    peak_activity_laps = timeline_analysis.get('peak_activity_laps', [])
    if peak_activity_laps:
        print(f"\n[HOT] é«˜æ´»å‹•åœˆæ•¸åˆ†æ (äº‹ä»¶æ•¸ >= 3):")
        for peak in peak_activity_laps[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            print(f"   åœˆæ•¸ {peak['lap']}: {peak['incident_count']} å€‹äº‹ä»¶ - {', '.join(peak['incidents'])}")


def save_all_incidents_raw_data(analysis_result, data_loader):
    """ä¿å­˜æ‰€æœ‰äº‹ä»¶åŸå§‹æ•¸æ“šç‚ºJSONæ ¼å¼"""
    if not analysis_result:
        print("[ERROR] ç„¡åˆ†æçµæœå¯ä¿å­˜")
        return
    
    try:
        session_info = analysis_result.get("session_info", {})
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        filename = f"raw_data_all_incidents_{session_info.get('year', '2025')}_{session_info.get('race', 'Unknown')}_{timestamp}.json"
        
        # æº–å‚™JSONæ•¸æ“š
        json_data = {
            "analysis_type": "all_incidents_analysis",
            "function": "4.5",
            "timestamp": datetime.now().isoformat(),
            "session_info": clean_for_json(session_info),
            "incident_analysis": {
                "total_incidents": analysis_result.get("total_incidents", 0),
                "incident_statistics": clean_for_json(analysis_result.get("incident_statistics", {})),
                "timeline_analysis": clean_for_json(analysis_result.get("timeline_analysis", {})),
                "has_critical_incidents": analysis_result.get("incident_statistics", {}).get("most_severe_incidents", 0) > 0
            },
            "all_incidents": clean_for_json(analysis_result.get("all_incidents", [])),
            "metadata": {
                "analysis_date": datetime.now().isoformat(),
                "data_source": "FastF1 + OpenF1",
                "severity_levels": ["MINIMAL", "LOW", "MEDIUM", "HIGH", "CRITICAL"],
                "incident_categories": ["SAFETY_CAR", "YELLOW_FLAG", "RED_FLAG", "DRS_EVENT", "TRACK_LIMITS", "PENALTY", "INCIDENT", "PIT_EVENT", "WEATHER", "RACE_START", "RACE_END", "OTHER"],
                "version": "1.0"
            }
        }
        
        # ä¿å­˜JSONæ–‡ä»¶
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ åŸå§‹æ•¸æ“šå·²ä¿å­˜è‡³: {filename}")
        print(f"[INFO] JSONåŒ…å« {len(json_data.get('all_incidents', []))} é …å®Œæ•´äº‹ä»¶è¨˜éŒ„")
        
    except Exception as e:
        print(f"[ERROR] ä¿å­˜JSONæ–‡ä»¶å¤±æ•—: {e}")


def run_all_incidents_analysis(data_loader):
    """åŸ·è¡Œæ‰€æœ‰äº‹ä»¶è©³ç´°åˆ—è¡¨åˆ†æçš„ä¸»å‡½æ•¸"""
    try:
        print("\n[LIST] é–‹å§‹æ‰€æœ‰äº‹ä»¶è©³ç´°åˆ—è¡¨åˆ†æ...")
        
        # æª¢æŸ¥æ•¸æ“šè¼‰å…¥å™¨
        if not data_loader:
            print("[ERROR] æ•¸æ“šè¼‰å…¥å™¨æœªåˆå§‹åŒ–")
            return False
        
        # åˆ†ææ‰€æœ‰äº‹ä»¶æ•¸æ“š
        analysis_result = analyze_all_incidents_data(data_loader)
        
        if not analysis_result:
            print("[ERROR] æ‰€æœ‰äº‹ä»¶åˆ†æå¤±æ•—")
            return False
        
        # é¡¯ç¤ºåˆ†æçµæœ
        display_all_incidents_table(analysis_result)
        
        # ä¿å­˜åŸå§‹æ•¸æ“š
        save_all_incidents_raw_data(analysis_result, data_loader)
        
        print("\n[SUCCESS] æ‰€æœ‰äº‹ä»¶è©³ç´°åˆ—è¡¨åˆ†æå®Œæˆ")
        return True
        
    except Exception as e:
        print(f"[ERROR] åŸ·è¡Œæ‰€æœ‰äº‹ä»¶è©³ç´°åˆ—è¡¨åˆ†ææ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    print("[WARNING] æ­¤æ¨¡çµ„éœ€è¦é€šéä¸»ç¨‹å¼èª¿ç”¨")
    print("è«‹ä½¿ç”¨ F1_Analysis_Main_Menu.bat é¸æ“‡åŠŸèƒ½ 4.5")

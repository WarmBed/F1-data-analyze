#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
F1 Analysis API - å®Œæ•´ç‰ˆæœ¬
æ”¯æ´æ‰€æœ‰å¹´ä»½è³½äº‹ã€è³½æ®µé¸æ“‡çš„ REST API ä»‹é¢

ç‰ˆæœ¬: 2.0 
ä½œè€…: F1 Analysis Team
æ”¯æ´åŠŸèƒ½: 1-22 + æ‰€æœ‰å­åŠŸèƒ½ (4.1-4.5, 6.1-6.7, 7.1-7.2, 11.1-11.2, 12.1-12.2, 14.1-14.4, 16.1-16.4)
"""

import os
import sys
import json
import traceback
import logging
import asyncio
import subprocess
from datetime import datetime
from typing import Optional, List, Dict, Any, Union

# FastAPI ç›¸é—œå°å…¥
from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

# è¨­å®šæ—¥èªŒ - éµå¾ªæ ¸å¿ƒé–‹ç™¼åŸå‰‡ï¼Œè¼¸å‡ºåˆ° logs/ ç›®éŒ„
os.makedirs('logs', exist_ok=True)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('logs/f1_api.log', encoding='utf-8'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# FastAPI æ‡‰ç”¨åˆå§‹åŒ–
app = FastAPI(
    title="F1 Analysis API",
    description="F1 è³½äº‹æ•¸æ“šåˆ†æ REST API - å®Œæ•´åŠŸèƒ½ç‰ˆæœ¬",
    version="2.0.0"
)

# CORS è¨­å®š
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# è¨­å®šå¸¸æ•¸
DEBUG_MODE = True
API_VERSION = "2.0.0"

# æ”¯æ´çš„å¹´ä»½å’Œé¸é …
RACE_OPTIONS = {
    2024: ["Bahrain", "Saudi Arabia", "Australia", "Japan", "China", "Miami", "Emilia Romagna", 
           "Monaco", "Canada", "Spain", "Austria", "Great Britain", "Hungary", "Belgium", 
           "Netherlands", "Italy", "Azerbaijan", "Singapore", "United States", "Mexico", 
           "Brazil", "Las Vegas", "Qatar", "Abu Dhabi"],
    2025: ["Australia", "China", "Japan", "Bahrain", "Saudi Arabia", "Miami", "Emilia Romagna",
           "Monaco", "Canada", "Spain", "Austria", "Great Britain", "Hungary", "Belgium",
           "Netherlands", "Italy", "Azerbaijan", "Singapore", "United States", "Mexico",
           "Brazil", "Abu Dhabi"]
}

SESSION_TYPES = ["R", "Q", "FP1", "FP2", "FP3", "S"]

# Pydantic æ¨¡å‹
class AnalysisRequest(BaseModel):
    """åˆ†æè«‹æ±‚æ¨¡å‹"""
    year: int = Field(..., description="è³½å­£å¹´ä»½", ge=2024, le=2025)
    race: str = Field(..., description="è³½äº‹åç¨±")
    session: str = Field(..., description="è³½æ®µé¡å‹")
    function_id: Union[str, int] = Field(..., description="åŠŸèƒ½ç·¨è™Ÿ")
    driver1: Optional[str] = Field(None, description="è»Šæ‰‹1ä»£ç¢¼ (å–®è»Šæ‰‹åˆ†ææˆ–é›™è»Šæ‰‹æ¯”è¼ƒç”¨)")
    driver2: Optional[str] = Field(None, description="è»Šæ‰‹2ä»£ç¢¼ (é›™è»Šæ‰‹æ¯”è¼ƒç”¨)")
    corner_number: Optional[int] = Field(None, description="å½é“ç·¨è™Ÿ (å½é“åˆ†æç”¨)")
    
    class Config:
        schema_extra = {
            "example": {
                "year": 2024,
                "race": "Bahrain",
                "session": "R",
                "function_id": "5",
                "driver1": "VER",
                "driver2": None,
                "corner_number": None
            }
        }

class APIResponse(BaseModel):
    """API éŸ¿æ‡‰æ¨¡å‹"""
    success: bool
    message: str
    data: Optional[Dict[str, Any]] = None
    timestamp: str = Field(default_factory=lambda: datetime.now().isoformat())

def log_message(message: str, level: str = "INFO"):
    """è¨˜éŒ„è¨Šæ¯"""
    timestamp = datetime.now().strftime("%H:%M:%S")
    level_emoji = {
        "DEBUG": "ğŸ”",
        "INFO": "â„¹ï¸", 
        "WARNING": "âš ï¸",
        "ERROR": "âŒ",
        "SUCCESS": "âœ…",
        "CRITICAL": "ğŸš¨"
    }
    emoji = level_emoji.get(level, "ğŸ“")
    print(f"[{timestamp}] {emoji} [{level}] {message}")
    
    if level == "DEBUG":
        logger.debug(message)
    elif level == "INFO":
        logger.info(message)
    elif level == "WARNING":
        logger.warning(message)
    elif level == "ERROR":
        logger.error(message)
    elif level == "CRITICAL":
        logger.critical(message)
    else:
        logger.info(message)

def _process_analysis_result(result, start_time: float, function_id: Union[str, int], 
                           year: int, race: str, session: str) -> Dict[str, Any]:
    """è™•ç†åˆ†æçµæœçš„è¼”åŠ©å‡½æ•¸"""
    end_time = datetime.now().timestamp()
    execution_time = round(end_time - start_time, 2)
    
    if result and result.returncode == 0:
        log_message(f"åŠŸèƒ½ {function_id} åŸ·è¡ŒæˆåŠŸ", "SUCCESS")
        
        # å˜—è©¦è§£æè¼¸å‡ºä¸­çš„JSONæ•¸æ“š
        output_data = {}
        if result.stdout:
            try:
                # æŸ¥æ‰¾è¼¸å‡ºä¸­çš„JSONæª”æ¡ˆè·¯å¾‘
                lines = result.stdout.split('\n')
                json_files = []
                for line in lines:
                    if 'JSONè¼¸å‡ºå·²ä¿å­˜åˆ°:' in line or 'JSONè¼¸å‡ºå·²å„²å­˜åˆ°:' in line:
                        json_path = line.split(':')[-1].strip()
                        if os.path.exists(json_path):
                            json_files.append(json_path)
                
                # è®€å–JSONæª”æ¡ˆ
                if json_files:
                    for json_file in json_files:
                        try:
                            with open(json_file, 'r', encoding='utf-8') as f:
                                file_data = json.load(f)
                                output_data[os.path.basename(json_file)] = file_data
                        except Exception as e:
                            log_message(f"è®€å–JSONæª”æ¡ˆ {json_file} å¤±æ•—: {e}", "WARNING")
                            
            except Exception as e:
                log_message(f"è§£æè¼¸å‡ºæ•¸æ“šå¤±æ•—: {e}", "WARNING")
        
        return {
            "success": True,
            "message": f"åŠŸèƒ½ {function_id} åˆ†æå®Œæˆ",
            "execution_time": f"{execution_time}ç§’",
            "function_id": str(function_id),
            "parameters": {
                "year": year,
                "race": race,
                "session": session
            },
            "output": result.stdout,
            "json_data": output_data if output_data else None
        }
    else:
        error_msg = result.stderr if result and result.stderr else "æœªçŸ¥éŒ¯èª¤"
        log_message(f"åŠŸèƒ½ {function_id} åŸ·è¡Œå¤±æ•—: {error_msg}", "ERROR")
        
        return {
            "success": False,
            "message": f"åŠŸèƒ½ {function_id} åˆ†æå¤±æ•—",
            "error": error_msg,
            "execution_time": f"{execution_time}ç§’",
            "function_id": str(function_id),
            "parameters": {
                "year": year,
                "race": race,
                "session": session
            }
        }

@app.get("/", response_model=APIResponse)
async def root():
    """API æ ¹è·¯ç”±"""
    supported_modules = [
        # åŸºç¤åˆ†ææ¨¡çµ„ (1-4)
        "rain_analysis", "track_path_analysis", "pitstop_analysis", "accident_analysis",
        # å–®è»Šæ‰‹åˆ†ææ¨¡çµ„ (5-13)
        "single_driver_analysis", "single_driver_telemetry", "driver_comparison", 
        "race_position_changes", "race_overtaking_statistics", "single_driver_overtaking",
        "single_dnf_analysis", "corner_detailed_analysis", "single_driver_all_corners",
        # å…¨éƒ¨è»Šæ‰‹åˆ†ææ¨¡çµ„ (14-17)
        "all_drivers_analysis", "driver_statistics_overview", "driver_telemetry_statistics",
        "driver_overtaking_analysis", "driver_fastest_lap_ranking", "corner_speed_analysis",
        # è¶…è»Šåˆ†æå­æ¨¡çµ„ (16.1-16.4)
        "all_drivers_annual_overtaking", "all_drivers_overtaking_performance",
        "all_drivers_overtaking_visualization", "all_drivers_overtaking_trends",
        # DNFåˆ†æ (17)
        "all_dnf_analysis"
    ]
    
    return APIResponse(
        success=True,
        message="F1 Analysis API is running",
        data={
            "version": API_VERSION,
            "description": "F1 è³½äº‹æ•¸æ“šåˆ†æ REST API - å®Œæ•´åŠŸèƒ½ç‰ˆæœ¬",
            "debug_mode": DEBUG_MODE,
            "endpoints": ["/analyze", "/health", "/modules", "/supported-functions", "/drivers"],
            "supported_modules": supported_modules,
            "total_modules": len(supported_modules),
            "supported_years": list(RACE_OPTIONS.keys()),
            "session_types": SESSION_TYPES
        }
    )

@app.get("/health")
async def health_check():
    """å¥åº·æª¢æŸ¥ç«¯é»"""
    return {"status": "healthy", "timestamp": datetime.now().isoformat()}

@app.get("/modules")
async def get_modules():
    """ç²å–æ”¯æ´çš„æ¨¡çµ„åˆ—è¡¨"""
    modules = {
        "basic_analysis": {
            "1": "é™é›¨å¼·åº¦åˆ†æ (Rain Intensity Analysis)",
            "2": "è³½é“è·¯ç·šåˆ†æ (Track Path Analysis)", 
            "3": "é€²ç«™ç­–ç•¥åˆ†æ (Pitstop Strategy Analysis)",
            "3.1": "å–®å ´è³½äº‹é€²ç«™çµ±è¨ˆ (Race Pitstop Statistics)",
            "4": "ç¨ç«‹äº‹æ•…åˆ†æ (Independent Accident Analysis)",
            "4.1": "é—œéµäº‹ä»¶æ‘˜è¦ (Key Events Summary)",
            "4.2": "ç‰¹æ®Šäº‹ä»¶å ±å‘Š (Special Incident Reports)",
            "4.3": "è»Šæ‰‹åš´é‡ç¨‹åº¦åˆ†æ•¸çµ±è¨ˆ (Driver Severity Scores)",
            "4.4": "è»ŠéšŠé¢¨éšªåˆ†æ•¸çµ±è¨ˆ (Team Risk Scores)",
            "4.5": "æ‰€æœ‰äº‹ä»¶è©³ç´°åˆ—è¡¨ (All Incidents Summary)"
        },
        "single_driver_analysis": {
            "5": "å–®ä¸€è»Šæ‰‹ç¶œåˆåˆ†æ (Single Driver Comprehensive Analysis)",
            "6": "å–®ä¸€è»Šæ‰‹è©³ç´°é™æ¸¬åˆ†æ (Single Driver Detailed Telemetry)",
            "6.1": "è©³ç´°åœˆæ¬¡åˆ†æ (Complete Lap Analysis)",
            "6.2": "è©³ç´°è¼ªèƒç­–ç•¥åˆ†æ (Detailed Tire Strategy)",
            "6.3": "è¼ªèƒæ€§èƒ½è©³ç´°åˆ†æ (Tire Performance Analysis)",
            "6.4": "é€²ç«™è¨˜éŒ„ (Pitstop Records)",
            "6.5": "ç‰¹æ®Šäº‹ä»¶åˆ†æ (Special Events)",
            "6.6": "æœ€å¿«åœˆé€Ÿåº¦é™æ¸¬æ•¸æ“š (Fastest Lap Speed Data)",
            "6.7": "æŒ‡å®šåœˆæ¬¡å®Œæ•´é™æ¸¬æ•¸æ“š (Specific Lap Full Telemetry)",
            "7": "é›™è»Šæ‰‹æ¯”è¼ƒåˆ†æ (Two Driver Comparison)",
            "7.1": "é€Ÿåº¦å·®è·åˆ†æ + åŸå§‹æ•¸æ“š (Speed Gap Analysis + Raw Data)",
            "7.2": "è·é›¢å·®è·åˆ†æ + åŸå§‹æ•¸æ“š (Distance Gap Analysis + Raw Data)",
            "8": "è³½äº‹ä½ç½®è®ŠåŒ–åœ– + Raw Data (Race Position Changes Chart + Raw Data)",
            "9": "è³½äº‹è¶…è»Šçµ±è¨ˆåˆ†æ + Raw Data (Race Overtaking Statistics + Raw Data)",
            "10": "å–®ä¸€è»Šæ‰‹è¶…è»Šåˆ†æ (Single Driver Overtaking Analysis)",
            "11": "ç¨ç«‹å–®ä¸€è»Šæ‰‹DNFåˆ†æ (Independent Single Driver DNF)",
            "11.1": "è©³ç´°DNFèˆ‡è²¬ä»»äº‹æ•…åˆ†æ (Detailed DNF & Incident Analysis + Raw Data)",
            "11.2": "å¹´åº¦DNFçµ±è¨ˆæ‘˜è¦ (Annual DNF Statistics Summary + Raw Data)",
            "12": "å–®è³½äº‹æŒ‡å®šå½é“è©³ç´°åˆ†æ (Single Race Specific Corner Detailed Analysis)",
            "12.1": "å–®ä¸€è»Šæ‰‹è©³ç´°å½é“åˆ†æ (Single Driver Corner Analysis + JSON)",
            "12.2": "åœ˜éšŠè»Šæ‰‹å°æ¯”åˆ†æ (Team Drivers Corner Comparison + JSON)",
            "13": "å–®ä¸€è»Šæ‰‹æŒ‡å®šè³½äº‹å…¨éƒ¨å½é“è©³ç´°åˆ†æ (Single Driver All Corners Detailed Analysis)"
        },
        "all_drivers_analysis": {
            "14": "æ‰€æœ‰è»Šæ‰‹ç¶œåˆåˆ†æ (All Drivers Comprehensive Analysis)",
            "14.1": "è»Šæ‰‹æ•¸æ“šçµ±è¨ˆç¸½è¦½ (Driver Statistics Overview)",
            "14.2": "è»Šæ‰‹é™æ¸¬è³‡æ–™çµ±è¨ˆ (Driver Telemetry Statistics)",
            "14.3": "è»Šæ‰‹è¶…è»Šåˆ†æ (Driver Overtaking Analysis)",
            "14.4": "æœ€é€Ÿåœˆæ’ååˆ†æ (Fastest Lap Ranking Analysis)",
            "14.9": "å®Œæ•´ç¶œåˆåˆ†æ (Full Comprehensive Analysis)",
            "15": "å½é“é€Ÿåº¦åˆ†æ (Corner Speed Analysis)",
            "16": "å…¨éƒ¨è»Šæ‰‹è¶…è»Šåˆ†æ (All Drivers Overtaking)",
            "16.1": "å¹´åº¦è¶…è»Šçµ±è¨ˆ (Annual Overtaking Statistics)",
            "16.2": "è¡¨ç¾æ¯”è¼ƒåˆ†æ (Performance Comparison)",
            "16.3": "è¦–è¦ºåŒ–åˆ†æ (Visualization Analysis)",
            "16.4": "è¶¨å‹¢åˆ†æ (Trends Analysis)",
            "17": "ç¨ç«‹å…¨éƒ¨è»Šæ‰‹DNFåˆ†æ (Independent All Drivers DNF)"
        },
        "system_functions": {
            "18": "é‡æ–°è¼‰å…¥è³½äº‹æ•¸æ“š (Reload Race Data)",
            "19": "é¡¯ç¤ºæ¨¡çµ„ç‹€æ…‹ (Show Module Status)",
            "20": "é¡¯ç¤ºå¹«åŠ©ä¿¡æ¯ (Show Help)",
            "21": "è¶…è»Šæš«å­˜ç®¡ç† (Overtaking Cache Management)",
            "22": "DNFæš«å­˜ç®¡ç† (DNF Cache Management)"
        }
    }
    
    return APIResponse(
        success=True,
        message="æ”¯æ´çš„åˆ†ææ¨¡çµ„åˆ—è¡¨",
        data=modules
    )

@app.get("/supported-functions")
async def get_supported_functions():
    """ç²å–æ‰€æœ‰æ”¯æ´çš„åŠŸèƒ½ç·¨è™Ÿ"""
    functions = [
        # åŸºç¤åŠŸèƒ½ 1-22
        "1", "2", "3", "3.1", "4", "5", "6", "7", "8", "9", "10", 
        "11", "12", "13", "14", "15", "16", "17", "18", "19", "20", "21", "22",
        # äº‹æ•…åˆ†æå­åŠŸèƒ½ 4.x
        "4.1", "4.2", "4.3", "4.4", "4.5",
        # é™æ¸¬åˆ†æå­åŠŸèƒ½ 6.x
        "6.1", "6.2", "6.3", "6.4", "6.5", "6.6", "6.7",
        # è»Šæ‰‹æ¯”è¼ƒå­åŠŸèƒ½ 7.x
        "7.1", "7.2",
        # DNFåˆ†æå­åŠŸèƒ½ 11.x
        "11.1", "11.2",
        # å½é“åˆ†æå­åŠŸèƒ½ 12.x
        "12.1", "12.2",
        # è»Šæ‰‹çµ±è¨ˆå­åŠŸèƒ½ 14.x
        "14.1", "14.2", "14.3", "14.4", "14.9",
        # è¶…è»Šåˆ†æå­åŠŸèƒ½ 16.x
        "16.1", "16.2", "16.3", "16.4"
    ]
    
    return APIResponse(
        success=True,
        message="æ‰€æœ‰æ”¯æ´çš„åŠŸèƒ½ç·¨è™Ÿ",
        data={
            "functions": functions,
            "total_functions": len(functions),
            "categories": {
                "basic": ["1", "2", "3", "3.1"],
                "accident": ["4"] + [f"4.{i}" for i in range(1, 6)],
                "single_driver": ["5", "6", "7", "8", "9", "10", "11", "12", "13"] + 
                               [f"6.{i}" for i in range(1, 8)] + ["7.1", "7.2"] + 
                               ["11.1", "11.2"] + ["12.1", "12.2"],
                "all_drivers": ["14", "15", "16", "17"] + 
                              [f"14.{i}" for i in [1, 2, 3, 4, 9]] + 
                              [f"16.{i}" for i in range(1, 5)],
                "system": ["18", "19", "20", "21", "22"]
            },
            "parameter_requirements": {
                "single_driver_functions": ["5", "6", "8", "9", "10", "11", "13"] + 
                                         [f"6.{i}" for i in range(1, 8)] + ["11.1", "11.2"],
                "dual_driver_functions": ["7", "7.1", "7.2"],
                "corner_analysis_functions": ["12.1", "12.2"],
                "note": "åƒæ•¸ driver1, driver2, corner_number ç”± API æ¥æ”¶ä½†ä¸å‚³éçµ¦ä¸»ç¨‹å¼ï¼Œå„æ¨¡çµ„æœƒåœ¨å…§éƒ¨è‡ªå‹•è™•ç†è»Šæ‰‹å’Œå½é“é¸æ“‡"
            }
        }
    )

@app.get("/drivers")
async def get_common_drivers():
    """ç²å–å¸¸ç”¨è»Šæ‰‹ä»£ç¢¼åˆ—è¡¨"""
    drivers = {
        "2024_drivers": {
            "VER": "Max Verstappen (Red Bull)",
            "PER": "Sergio Perez (Red Bull)",
            "LEC": "Charles Leclerc (Ferrari)",
            "SAI": "Carlos Sainz (Ferrari)",
            "NOR": "Lando Norris (McLaren)",
            "PIA": "Oscar Piastri (McLaren)",
            "RUS": "George Russell (Mercedes)",
            "HAM": "Lewis Hamilton (Mercedes)",
            "ALO": "Fernando Alonso (Aston Martin)",
            "STR": "Lance Stroll (Aston Martin)",
            "TSU": "Yuki Tsunoda (AlphaTauri)",
            "RIC": "Daniel Ricciardo (AlphaTauri)",
            "ALB": "Alexander Albon (Williams)",
            "SAR": "Logan Sargeant (Williams)",
            "HUL": "Nico Hulkenberg (Haas)",
            "MAG": "Kevin Magnussen (Haas)",
            "GAS": "Pierre Gasly (Alpine)",
            "OCO": "Esteban Ocon (Alpine)",
            "BOT": "Valtteri Bottas (Alfa Romeo)",
            "ZHO": "Zhou Guanyu (Alfa Romeo)"
        },
        "2025_drivers": {
            "VER": "Max Verstappen (Red Bull)",
            "PER": "Sergio Perez (Red Bull)",
            "LEC": "Charles Leclerc (Ferrari)",
            "HAM": "Lewis Hamilton (Ferrari)",
            "NOR": "Lando Norris (McLaren)",
            "PIA": "Oscar Piastri (McLaren)",
            "RUS": "George Russell (Mercedes)",
            "ANT": "Andrea Kimi Antonelli (Mercedes)",
            "ALO": "Fernando Alonso (Aston Martin)",
            "STR": "Lance Stroll (Aston Martin)"
        },
        "common_codes": ["VER", "LEC", "HAM", "NOR", "RUS", "ALO", "PER", "SAI", "PIA", "GAS"]
    }
    
    return APIResponse(
        success=True,
        message="æ”¯æ´çš„è»Šæ‰‹ä»£ç¢¼åˆ—è¡¨",
        data=drivers
    )

@app.post("/analyze", response_model=APIResponse)
async def analyze_data(request: AnalysisRequest):
    """åŸ·è¡ŒF1æ•¸æ“šåˆ†æ"""
    log_message(f"æ”¶åˆ°åˆ†æè«‹æ±‚: åŠŸèƒ½{request.function_id}, {request.year} {request.race} {request.session}", "INFO")
    
    try:
        # é©—è­‰å¹´ä»½
        if request.year not in RACE_OPTIONS:
            raise HTTPException(
                status_code=400, 
                detail=f"ä¸æ”¯æ´çš„å¹´ä»½: {request.year}ã€‚æ”¯æ´çš„å¹´ä»½: {list(RACE_OPTIONS.keys())}"
            )
        
        # é©—è­‰è³½äº‹
        if request.race not in RACE_OPTIONS[request.year]:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æ´çš„è³½äº‹: {request.race}ã€‚{request.year}å¹´æ”¯æ´çš„è³½äº‹: {RACE_OPTIONS[request.year]}"
            )
        
        # é©—è­‰è³½æ®µé¡å‹
        if request.session not in SESSION_TYPES:
            raise HTTPException(
                status_code=400,
                detail=f"ä¸æ”¯æ´çš„è³½æ®µé¡å‹: {request.session}ã€‚æ”¯æ´çš„é¡å‹: {SESSION_TYPES}"
            )
        
        # ä½¿ç”¨çµ±ä¸€çš„åŠŸèƒ½æ˜ å°„å™¨ - ç¬¦åˆæ ¸å¿ƒé–‹ç™¼åŸå‰‡çš„åƒæ•¸åŒ–æ¨¡å¼
        start_time = datetime.now().timestamp()
        
        try:
            # åˆå§‹åŒ–æ•¸æ“šè¼‰å…¥å™¨
            current_dir = os.path.dirname(os.path.abspath(__file__))
            modules_dir = os.path.join(current_dir, 'modules')
            if modules_dir not in sys.path:
                sys.path.insert(0, modules_dir)
            
            # å‹•æ…‹å°å…¥æ ¸å¿ƒæ¨¡çµ„
            log_message("è¼‰å…¥æ ¸å¿ƒæ¨¡çµ„...", "INFO")
            from modules.compatible_data_loader import CompatibleF1DataLoader
            from modules.function_mapper import F1AnalysisFunctionMapper
            
            # å‰µå»ºæ•¸æ“šè¼‰å…¥å™¨ä¸¦è¼‰å…¥æ•¸æ“š
            data_loader = CompatibleF1DataLoader()
            
            log_message(f"è¼‰å…¥æ•¸æ“š: {request.year} {request.race} {request.session}", "INFO")
            if not data_loader.load_race_data(request.year, request.race, request.session):
                return APIResponse(
                    success=False,
                    message="æ•¸æ“šè¼‰å…¥å¤±æ•—",
                    data={
                        "error": f"ç„¡æ³•è¼‰å…¥ {request.year} {request.race} {request.session} çš„æ•¸æ“š",
                        "function_id": str(request.function_id),
                        "parameters": {
                            "year": request.year,
                            "race": request.race,
                            "session": request.session
                        }
                    }
                )
            
            # å‰µå»ºåŠŸèƒ½æ˜ å°„å™¨ - æ ¹æ“šæ ¸å¿ƒé–‹ç™¼åŸå‰‡
            log_message("åˆå§‹åŒ–åŠŸèƒ½æ˜ å°„å™¨...", "INFO")
            mapper = F1AnalysisFunctionMapper(
                data_loader=data_loader,
                dynamic_team_mapping=None,  # å°‡å¾æ•¸æ“šè¼‰å…¥å™¨ç²å–
                f1_analysis_instance=None,  # å°‡åœ¨æ˜ å°„å™¨å…§éƒ¨å‰µå»º
                driver=request.driver1,     # ä¸»è¦è»Šæ‰‹
                driver2=request.driver2     # æ¬¡è¦è»Šæ‰‹
            )
            
            # åŸ·è¡Œåˆ†æåŠŸèƒ½ - éµå¾ªçµ±ä¸€åŸ·è¡Œæ¨™æº–
            log_message(f"åŸ·è¡ŒåŠŸèƒ½: {request.function_id}", "INFO")
            
            # è¨­å®šåŸ·è¡Œåƒæ•¸ - ç¢ºä¿å…¼å®¹æ€§
            execution_params = {
                "function_id": request.function_id,
                "driver1": request.driver1,
                "driver2": request.driver2,
                "corner_number": request.corner_number,
                "year": request.year,
                "race": request.race,
                "session": request.session
            }
            
            # å˜—è©¦åŸ·è¡Œåˆ†æï¼Œå¦‚æœå¤±æ•—å‰‡å˜—è©¦ä¸åŒåƒæ•¸çµ„åˆ
            analysis_result = None
            try:
                # é¦–å…ˆå˜—è©¦å®Œæ•´åƒæ•¸
                analysis_result = mapper.execute_function_by_number(
                    function_id=request.function_id,
                    driver1=request.driver1,
                    driver2=request.driver2,
                    corner_number=request.corner_number,
                    show_detailed_output=True,  # API é è¨­é¡¯ç¤ºè©³ç´°è¼¸å‡º
                    year=request.year,
                    race=request.race,
                    session=request.session
                )
            except TypeError as te:
                log_message(f"åƒæ•¸éŒ¯èª¤ï¼Œå˜—è©¦ç°¡åŒ–åƒæ•¸: {te}", "WARNING")
                # å¦‚æœæœ‰åƒæ•¸å•é¡Œï¼Œå˜—è©¦ç°¡åŒ–åƒæ•¸
                try:
                    analysis_result = mapper.execute_function_by_number(
                        function_id=request.function_id,
                        driver1=request.driver1,
                        driver2=request.driver2,
                        corner_number=request.corner_number
                    )
                except Exception as e2:
                    log_message(f"ç°¡åŒ–åƒæ•¸ä¹Ÿå¤±æ•—: {e2}", "ERROR")
                    analysis_result = {
                        "success": False,
                        "message": f"åŠŸèƒ½åŸ·è¡Œå¤±æ•—: åƒæ•¸éŒ¯èª¤",
                        "error": f"TypeError: {te}, ç°¡åŒ–å˜—è©¦: {e2}"
                    }
            except Exception as e:
                log_message(f"åŸ·è¡Œç•°å¸¸: {e}", "ERROR")
                analysis_result = {
                    "success": False,
                    "message": f"åŠŸèƒ½åŸ·è¡Œå¤±æ•—",
                    "error": str(e)
                }
            
            # ç¢ºä¿åˆ†æçµæœç‚ºå­—å…¸æ ¼å¼
            if not isinstance(analysis_result, dict):
                log_message("åˆ†æçµæœæ ¼å¼ç•°å¸¸ï¼Œä½¿ç”¨é»˜èªæ ¼å¼", "WARNING")
                analysis_result = {
                    "success": False,
                    "message": "åˆ†æçµæœæ ¼å¼ç•°å¸¸",
                    "error": f"è¿”å›çµæœé¡å‹: {type(analysis_result)}",
                    "function_id": str(request.function_id),
                    "raw_result": str(analysis_result)[:500]  # æˆªå–å‰500å­—ç¬¦ä½œç‚ºèª¿è©¦ä¿¡æ¯
                }
            
            # è¨ˆç®—åŸ·è¡Œæ™‚é–“
            end_time = datetime.now().timestamp()
            execution_time = round(end_time - start_time, 2)
            
            # å¢å¼·åˆ†æçµæœ - æ·»åŠ åŸ·è¡Œå…ƒæ•¸æ“š
            analysis_result.update({
                "execution_time": f"{execution_time}ç§’",
                "function_id": str(request.function_id),
                "parameters": {
                    "year": request.year,
                    "race": request.race,
                    "session": request.session,
                    "driver1": request.driver1,
                    "driver2": request.driver2,
                    "corner_number": request.corner_number
                },
                "api_version": API_VERSION,
                "timestamp": datetime.now().isoformat(),
                "cache_used": analysis_result.get("cache_used", False)
            })
            
            # å˜—è©¦è¼‰å…¥ JSON æ•¸æ“š - å¢åŠ æ•¸æ“šè±å¯Œåº¦
            if analysis_result.get("success"):
                try:
                    # æŸ¥æ‰¾ json ç›®éŒ„ä¸­çš„ç›¸é—œæ–‡ä»¶
                    json_dir = os.path.join(os.getcwd(), "json")
                    if os.path.exists(json_dir):
                        # æŸ¥æ‰¾æœ€æ–°çš„ç›¸é—œ JSON æ–‡ä»¶
                        json_files = []
                        for file in os.listdir(json_dir):
                            if file.endswith('.json') and str(request.function_id) in file:
                                json_path = os.path.join(json_dir, file)
                                json_files.append(json_path)
                        
                        # è¼‰å…¥æ‰¾åˆ°çš„ JSON æ–‡ä»¶
                        if json_files:
                            analysis_result["json_files"] = []
                            for json_file in json_files[:3]:  # æœ€å¤š3å€‹æ–‡ä»¶ï¼Œé¿å…éå¤§
                                try:
                                    with open(json_file, 'r', encoding='utf-8') as f:
                                        json_data = json.load(f)
                                        analysis_result["json_files"].append({
                                            "filename": os.path.basename(json_file),
                                            "path": json_file,
                                            "data": json_data
                                        })
                                        log_message(f"æˆåŠŸè¼‰å…¥ JSON æ–‡ä»¶: {os.path.basename(json_file)}", "SUCCESS")
                                except Exception as e:
                                    log_message(f"è¼‰å…¥ JSON æ–‡ä»¶å¤±æ•— {json_file}: {e}", "WARNING")
                        else:
                            log_message(f"æœªæ‰¾åˆ°åŠŸèƒ½ {request.function_id} çš„ JSON æ–‡ä»¶", "WARNING")
                    else:
                        log_message("json ç›®éŒ„ä¸å­˜åœ¨", "WARNING")
                except Exception as e:
                    log_message(f"æœç´¢ JSON æ–‡ä»¶æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}", "WARNING")
            
            # é©—è­‰åˆ†æçµæœ
            if not analysis_result.get("success"):
                log_message(f"åŠŸèƒ½ {request.function_id} åŸ·è¡Œå¤±æ•—: {analysis_result.get('message', 'æœªçŸ¥éŒ¯èª¤')}", "ERROR")
            else:
                log_message(f"åŠŸèƒ½ {request.function_id} åŸ·è¡ŒæˆåŠŸ", "SUCCESS")
            
        except ImportError as e:
            log_message(f"æ¨¡çµ„è¼‰å…¥å¤±æ•—: {str(e)}", "ERROR")
            analysis_result = {
                "success": False,
                "message": "ç³»çµ±æ¨¡çµ„è¼‰å…¥å¤±æ•—",
                "error": str(e),
                "function_id": str(request.function_id),
                "traceback": traceback.format_exc() if DEBUG_MODE else None
            }
        except Exception as e:
            log_message(f"åˆ†æåŸ·è¡Œç•°å¸¸: {str(e)}", "ERROR")
            analysis_result = {
                "success": False,
                "message": "åˆ†æåŸ·è¡Œå¤±æ•—",
                "error": str(e),
                "function_id": str(request.function_id),
                "traceback": traceback.format_exc() if DEBUG_MODE else None
            }
        
        return APIResponse(
            success=analysis_result.get("success", False),
            message=analysis_result.get("message", "åˆ†æå®Œæˆ"),
            data=analysis_result
        )
        
    except subprocess.TimeoutExpired:
        log_message(f"åˆ†æè¶…æ™‚: åŠŸèƒ½ {request.function_id}", "ERROR")
        return APIResponse(
            success=False,
            message="åˆ†æè¶…æ™‚",
            data={
                "error": "åˆ†æåŸ·è¡Œè¶…é5åˆ†é˜æ™‚é–“é™åˆ¶",
                "function_id": str(request.function_id)
            }
        )
        
    except Exception as e:
        log_message(f"åˆ†æåŸ·è¡Œç•°å¸¸: {str(e)}", "ERROR")
        log_message(traceback.format_exc(), "DEBUG")
        
        return APIResponse(
            success=False,
            message="åˆ†æåŸ·è¡Œå¤±æ•—",
            data={
                "error": str(e),
                "function_id": str(request.function_id),
                "traceback": traceback.format_exc() if DEBUG_MODE else None
            }
        )

# éŒ¯èª¤è™•ç†
@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """HTTP éŒ¯èª¤è™•ç†"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "success": False,
            "message": exc.detail,
            "timestamp": datetime.now().isoformat()
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """ä¸€èˆ¬éŒ¯èª¤è™•ç†"""
    log_message(f"æœªè™•ç†çš„éŒ¯èª¤: {str(exc)}", "ERROR")
    return JSONResponse(
        status_code=500,
        content={
            "success": False,
            "message": "å…§éƒ¨æœå‹™å™¨éŒ¯èª¤",
            "error": str(exc) if DEBUG_MODE else "Internal server error",
            "timestamp": datetime.now().isoformat()
        }
    )

if __name__ == "__main__":
    try:
        import uvicorn
    except ImportError:
        print("âŒ ç¼ºå°‘ uvicorn å¥—ä»¶")
        print("å®‰è£å‘½ä»¤: pip install uvicorn")
        sys.exit(1)
    
    try:
        import fastapi
        import pydantic
    except ImportError:
        print("âŒ ç¼ºå°‘ FastAPI ç›¸é—œå¥—ä»¶")
        print("å®‰è£å‘½ä»¤: pip install fastapi pydantic")
        sys.exit(1)
    
    log_message("ğŸš€ å•Ÿå‹• F1 Analysis API æœå‹™å™¨...", "INFO")
    log_message(f"ğŸ“‹ API ç‰ˆæœ¬: {API_VERSION}", "INFO")
    log_message(f"ğŸ”§ èª¿è©¦æ¨¡å¼: {DEBUG_MODE}", "INFO")
    log_message("ğŸ¯ æ ¸å¿ƒé–‹ç™¼åŸå‰‡: APIå®Œå…¨å¯å‘¼å«", "INFO")
    
    print("\nğŸ“‹ API ç«¯é»:")
    print("   â€¢ æ ¹ç«¯é»: http://localhost:8000/")
    print("   â€¢ åˆ†æç«¯é»: http://localhost:8000/analyze")
    print("   â€¢ å¥åº·æª¢æŸ¥: http://localhost:8000/health")
    print("   â€¢ APIæ–‡æª”: http://localhost:8000/docs")
    print("   â€¢ æ¨¡çµ„åˆ—è¡¨: http://localhost:8000/modules")
    print("\nğŸ”§ ä½¿ç”¨ Ctrl+C åœæ­¢æœå‹™å™¨")
    
    try:
        uvicorn.run(
            app,
            host="0.0.0.0",
            port=8000,
            log_level="info" if not DEBUG_MODE else "debug",
            reload=DEBUG_MODE
        )
    except KeyboardInterrupt:
        log_message("ğŸ›‘ API æœå‹™å™¨å·²åœæ­¢", "INFO")
    except Exception as e:
        log_message(f"âŒ API æœå‹™å™¨å•Ÿå‹•å¤±æ•—: {e}", "ERROR")
        sys.exit(1)
